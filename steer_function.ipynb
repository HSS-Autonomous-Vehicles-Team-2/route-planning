{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "from jetbot import ObjectDetector\n",
    "from jetbot import Robot\n",
    "import traitlets\n",
    "import ipywidgets.widgets as widgets\n",
    "from IPython.display import display\n",
    "from jetbot import Camera, bgr8_to_jpeg\n",
    "model = ObjectDetector('ssd_mobilenet_v2_coco.engine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jetbot import Camera\n",
    "camera = Camera.instance(width=300, height=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[{'label': 64, 'confidence': 0.6675812602043152, 'bbox': [0.32334965467453003, 0.3238368630409241, 0.5677865147590637, 0.7766782641410828]}, {'label': 86, 'confidence': 0.3881540596485138, 'bbox': [0.35922643542289734, 0.49570202827453613, 0.5629936456680298, 0.7788211107254028]}]]\n"
     ]
    }
   ],
   "source": [
    "detections = model(camera.value)\n",
    "print(detections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import traitlets\n",
    "import ipywidgets.widgets as widgets\n",
    "from IPython.display import display\n",
    "target_obj_tall = 1\n",
    "target_obj_short = 1\n",
    "obstacle_obj_1 = 64 #cup\n",
    "obstacle_obj_2 = 86 #plant\n",
    "Standard_Motor_speed = 0.35\n",
    "object_info_dict = {1:(\"tall_object\", 64), 86:(\"short_object\", 74), 44:(\"Apple\", 30), 64:(\"Banana\", 40)}\n",
    "image_widget = widgets.Image(format='jpeg', width=300, height=300)\n",
    "width = int(image_widget.width)\n",
    "height = int(image_widget.height)\n",
    "robot = Robot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leftTurn(incremental,delay):\n",
    "    robot.left(incremental) # arbitrary small value\n",
    "    time.sleep(delay) # can change, might want to go higher\n",
    "    robot.stop()\n",
    "    time.sleep(1.5*delay)\n",
    "    robot.forward(Standard_Motor_speed)\n",
    "    time.sleep(1.5*delay)\n",
    "    robot.stop()\n",
    "    time.sleep(1)\n",
    "    robot.right(incremental)\n",
    "    time.sleep(delay)\n",
    "    robot.stop()\n",
    "    time.sleep(delay)\n",
    "    robot.forward(Standard_Motor_speed)\n",
    "    \n",
    "def rightTurn(incremental, delay):\n",
    "    robot.right(incremental) # arbitrary small value\n",
    "    time.sleep(delay) # can change, might want to go higher\n",
    "    robot.stop()\n",
    "    time.sleep(1.5*delay)\n",
    "    robot.forward(Standard_Motor_speed)\n",
    "    time.sleep(1.5*delay)\n",
    "    robot.stop()\n",
    "    time.sleep(1)\n",
    "    robot.left(incremental) # arbitrary small value\n",
    "    time.sleep(delay)\n",
    "    robot.stop()\n",
    "    time.sleep(delay)\n",
    "    robot.forward(Standard_Motor_speed)\n",
    "    \n",
    "def detection_center(detection):\n",
    "    \"\"\"Computes the center x, y coordinates of the object\"\"\"\n",
    "    bbox = detection['bbox']\n",
    "    center_x = (bbox[0] + bbox[2]) / (2.0 - 0.5)\n",
    "    center_y = (bbox[1] + bbox[3]) / (2.0 - 0.5)\n",
    "    area = ((bbox[2] - bbox[0])*width)*((bbox[3] - bbox[1])*height)\n",
    "    return (center_x*width, center_y*height,area)\n",
    "\n",
    "def steer(filterred_obstacle_detection):\n",
    "    obstacle_centriod = []\n",
    "    obstacle_area = []\n",
    "    obstacle_label = []\n",
    "    center_frame =  width/2.0\n",
    "    print(\"Center frame is \" + str(center_frame))\n",
    "    for det in filterred_obstacle_detection:\n",
    "        center_x, center_y, area = detection_center(det)\n",
    "        obstacle_centriod.append(center_x)\n",
    "        print(det['label'])\n",
    "        print(\"Center_x \" +str(center_x))\n",
    "        print(\"Center_y \" + str(center_y))\n",
    "    obstacle_list_len = len(obstacle_centriod)\n",
    "    \n",
    "\n",
    "    if obstacle_list_len == 2:\n",
    "        center_x_0 = obstacle_centriod[0]\n",
    "        center_x_1 = obstacle_centriod[1]\n",
    "        if (center_x_0 < center_frame) and (center_x_1 < center_frame):\n",
    "            print(\"Right turn\")\n",
    "            rightTurn(0.25, 0.3)\n",
    "        elif (center_x_0 > center_frame) and (center_x_1 > center_frame):\n",
    "            print(\"Left turn\")\n",
    "            leftTurn(0.25,0.3)\n",
    "        else:\n",
    "            print(\"take a long turn\")\n",
    "            leftTurn(0.25, 0.5)\n",
    "\n",
    "        print(\"Found 2 obstacles in the frame\")\n",
    "        \n",
    "    elif obstacle_list_len == 1:\n",
    "        center_x = obstacle_centriod[0]\n",
    "        print(\"Found 1 obstacles in the frame\")\n",
    "        if center_x < center_frame:\n",
    "            print(\"Turning right\")\n",
    "            rightTurn(0.3, 0.3)\n",
    "        else:\n",
    "            print(\"Turning Left\")\n",
    "            leftTurn(0.3, 0.3) \n",
    "        print(\"Found 1 obstacles in the frame\")\n",
    "    else:\n",
    "        return\n",
    "def estimate_distance(detection):\n",
    "    focal_length = 105.0  #need to caliborate your camera to get this\n",
    "    obj_info = object_info_dict[detection['label']]\n",
    "    bbox = detection['bbox']  \n",
    "    obj_width = obj_info[1]\n",
    "    obj_width_in_img = width * (bbox[2] - bbox[0])        \n",
    "    dist = obj_width * focal_length / obj_width_in_img\n",
    "    return dist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute(change):\n",
    "    \n",
    "    image = change['new']\n",
    "    #gray= cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "    #blur = cv2.GaussianBlur(gray,(5,5),cv2.BORDER_DEFAULT)\n",
    "    # compute all detected objects\n",
    "    detections = model(image)\n",
    "    is_local_steering_in_progress =0\n",
    "    filtered_detections = []\n",
    "    filterred_obstacle_detection = []\n",
    "    print(\"Found \" + str(len(detections[0])) + \" objects\")\n",
    "    # visualized target and obstacle objects\n",
    "    for det in detections[0]:\n",
    "        bbox = det['bbox']\n",
    "        label = det['label']\n",
    "        print(label)\n",
    "        if(label == target_obj_tall or label == target_obj_short):\n",
    "            dist = estimate_distance(det)\n",
    "            filtered_detections.append(det)\n",
    "            cv2.rectangle(image, (int(width * bbox[0]), int(height * bbox[1])), (int(width * bbox[2]), int(height * bbox[3])), (0, 0, 255), 2)\n",
    "            cv2.putText(image, object_info_dict[label][0] + \":\" + \"{:.2f}\".format(dist), (int(width * bbox[0]), int(height * bbox[1]) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255),2)\n",
    "        elif(label == obstacle_obj_1 or label == obstacle_obj_2):\n",
    "            dist = estimate_distance(det)\n",
    "            is_local_steering_in_progress = 1;\n",
    "            filtered_detections.append(det)\n",
    "            filterred_obstacle_detection.append(det)\n",
    "            cv2.rectangle(image, (int(width * bbox[0]), int(height * bbox[1])), (int(width * bbox[2]), int(height * bbox[3])), (0, 255, 0), 2)\n",
    "            cv2.putText(image, object_info_dict[label][0] + \":\" + \"{:.2f}\".format(dist), (int(width * bbox[0]), int(height * bbox[1]) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0),2)\n",
    "        else:\n",
    "            cv2.rectangle(image, (int(width * bbox[0]), int(height * bbox[1])), (int(width * bbox[2]), int(height * bbox[3])), (255, 0, 0), 2)\n",
    "            cv2.putText(image, str(label), (int(width * bbox[0]), int(height * bbox[1]) + 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0),2)\n",
    "       \n",
    "    \n",
    "    # update image widget\n",
    "    #image_widget.value = bgr8_to_jpeg(image)\n",
    "    \n",
    "    #if(is_target_reached(filtered_detections)):\n",
    "    #    camera.unobserve_all()\n",
    "     #   robot.stop()\n",
    "     #   return\n",
    "    \n",
    "    # if in local steering mode, return\n",
    "    if(is_local_steering_in_progress):\n",
    "        steer(filterred_obstacle_detection)\n",
    "        is_local_steering_in_progress = 0\n",
    "        #robot.stop()\n",
    "        print(\"is_local_steering_in_progress\")\n",
    "        return\n",
    "    \n",
    "    \n",
    "    #if(is_local_steering_in_progress == False):\n",
    "     #   lock_and_move_to_target(filtered_detections)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "534d0b5ac2bf4f9d9cda8018ea40c593",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00\\x00\\x01\\x00\\x01\\x00\\x00\\xff\\xdb\\x00C\\x00\\x02\\x01\\x0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = widgets.Image(format='jpeg', width=400, height=400)  # this width and height doesn't necessarily have to match the camera\n",
    "\n",
    "camera_link = traitlets.dlink((camera, 'value'), (image, 'value'), transform=bgr8_to_jpeg)\n",
    "display(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 objects\n",
      "64\n",
      "64\n",
      "Center frame is 150.0\n",
      "64\n",
      "Center_x 142.6639199256897\n",
      "Center_y 195.04966139793396\n",
      "64\n",
      "Center_x 142.3884630203247\n",
      "Center_y 204.49676513671875\n",
      "Right turn\n",
      "Found 2 obstacles in the frame\n",
      "is_local_steering_in_progress\n"
     ]
    }
   ],
   "source": [
    "execute({'new': camera.value})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
